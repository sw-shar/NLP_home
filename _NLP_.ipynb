{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ВЫШКАКУРС_НПОО_NLP_Домашнее_задание_о_разметке_последовательностей.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spe9O4ZpVgUH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d36b8ed-7720-4ed4-b595-bc388934ce60"
      },
      "source": [
        "!pip freeze | grep \"^\\(scikit-learn\\|pandas\\|numpy\\|torch\\)==\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy==1.21.6\n",
            "pandas==1.3.5\n",
            "scikit-learn==1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwMsKbe87wAe"
      },
      "source": [
        "# Домашнее задание о разметке последовательностей.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT6Zwd_s85Qd"
      },
      "source": [
        "**Задача**: научиться автоматически выделять именованные сущности в художественной литературе.\n",
        "\n",
        "Подзадачи:\n",
        "* [в тетради приведён код] подготовить данные для обучения sequence labeling моделей\n",
        "* [в тетради приведён код] обучить, оценить бейзлайновую модель NER\n",
        "* реализовать модель, превосходящую по метрикам бейзлайновую модель.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmzxQDSe89tw"
      },
      "source": [
        "### получение данных\n",
        "\n",
        "Будем использовать набор с корпусом LitBank. Корпус собран из популярных художественных произведений на английском языке и сожержит разметку по именованным сущностям и событиям. Объем корпуса таков: 100 текстов по примерно 2000 слов каждый. \n",
        "\n",
        "Корпус описан в статьях:\n",
        "* David Bamman, Sejal Popat, Sheng Shen, An Annotated Dataset of Literary Entities http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/naacl2019_literary_entities.pdf\n",
        "* Matthew Sims, Jong Ho Park, David Bamman, Literary Event Detection,  http://people.ischool.berkeley.edu/~dbamman/pubs/pdf/acl2019_literary_events.pdf\n",
        "\n",
        "Корпус доступен в репозитории проекта:  https://github.com/dbamman/litbank\n",
        "\n",
        "Структура корпуса в репозитории такова. \n",
        "Первый уровень: \n",
        "* entities &mdash; разметка по сущностям.\n",
        "В корпусе используются 6 типов именованных сущностей: PER, LOC, ORG, FAC, GPE, VEH (имена, локации, организации, помещения, топонимы, средства перемещния), допускаются вложенные сущности. \n",
        "* events &mdash; разметка по событиям\n",
        "\n",
        "Второй уровень:\n",
        "* brat &mdash; рабочие файлы инструмента разметки brat, ann-файлы содержат разметку, txt-файлы – сырые тексты \n",
        "* tsv &mdash; tsv-файлы содержат разметку в IOB формате,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_62H46N0td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0848173a-767a-40ef-9400-c57d875e7597"
      },
      "source": [
        "!git clone https://github.com/dbamman/litbank\n",
        "\n",
        "!TRAIN_DATA_FPATH=\"train.bio\" && TEST_DATA_FPATH=\"test.bio\" \\\n",
        " && rm -f $TRAIN_DATA_FPATH $TEST_DATA_FPATH \\\n",
        " && FILES=$(ls -1 litbank/entities/tsv/*) && N_FILES=$(echo \"$FILES\" | wc -l) \\\n",
        " && N_TRAIN_FILES=$((N_FILES * 0,8)) && N_TEST_FILES=$((N_FILES * 0,2)) \\\n",
        " && TRAIN_FILES=$(echo \"$FILES\" | head -n $N_TRAIN_FILES) \\\n",
        " && TEST_FILES=$(echo \"$FILES\" | tail -n $N_TEST_FILES) \\\n",
        " && for fn in \"$TRAIN_FILES\"; do cut -d $'\\t' -f1,3 $fn >> $TRAIN_DATA_FPATH; done \\\n",
        " && for fn in \"$TEST_FILES\"; do cut -d $'\\t' -f1,3 $fn >> $TEST_DATA_FPATH; done\n",
        "\n",
        "TRAIN_DATA_FPATH = \"train.bio\"\n",
        "TEST_DATA_FPATH = \"test.bio\"\n",
        "\n",
        "!wc -l {TRAIN_DATA_FPATH} {TEST_DATA_FPATH}\n",
        "!head -n 3 {TRAIN_DATA_FPATH} {TEST_DATA_FPATH} | column -s $'\\t' -t"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'litbank'...\n",
            "remote: Enumerating objects: 1183, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 1183 (delta 15), reused 103 (delta 5), pack-reused 1056\u001b[K\n",
            "Receiving objects: 100% (1183/1183), 40.71 MiB | 19.11 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n",
            " 18049 train.bio\n",
            "  4744 test.bio\n",
            " 22793 total\n",
            "==> train.bio <==\n",
            "CHAPTER            O\n",
            "I                  O\n",
            "In                 O\n",
            "==> test.bio <==\n",
            "CHAPTER            O\n",
            "I                  O\n",
            "Mr                 B-PER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrvvvfSU-wMI"
      },
      "source": [
        "Посмотрим, как выглядит корпус"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx-jGB91Qpga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8c1f63-2a02-4838-a7b7-01c928a04f2c"
      },
      "source": [
        "print(\"==> train data part <==\")\n",
        "!grep -m 1 -B 10 -A 10 I-P {TRAIN_DATA_FPATH} \n",
        "\n",
        "print(\"\\n\\n==> test data part <==\")\n",
        "!grep -m 1 -B 10 -A 10 I-[^P] {TEST_DATA_FPATH} "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> train data part <==\n",
            ".\tO\n",
            "\n",
            "Michaelmas\tO\n",
            "term\tO\n",
            "lately\tO\n",
            "over\tO\n",
            ",\tO\n",
            "and\tO\n",
            "the\tO\n",
            "Lord\tB-PER\n",
            "Chancellor\tI-PER\n",
            "sitting\tO\n",
            "in\tO\n",
            "Lincoln\tO\n",
            "'s\tO\n",
            "Inn\tO\n",
            "Hall\tO\n",
            ".\tO\n",
            "\n",
            "Implacable\tO\n",
            "November\tO\n",
            "\n",
            "\n",
            "==> test data part <==\n",
            "marking\tO\n",
            "ink\tO\n",
            ",\tO\n",
            "retail\tO\n",
            "value\tO\n",
            "sixpence\tO\n",
            "(\tO\n",
            "price\tO\n",
            "in\tO\n",
            "Verloc\tB-FAC\n",
            "’s\tI-FAC\n",
            "shop\tI-FAC\n",
            "one-and-sixpence\tO\n",
            ")\tO\n",
            ",\tO\n",
            "which\tO\n",
            ",\tO\n",
            "once\tO\n",
            "outside\tO\n",
            ",\tO\n",
            "he\tO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k_qCcWq-3mg"
      },
      "source": [
        "Данные &mdash; набор текстов английской литературы. \n",
        "* тексты поделены на предложения, предложения отделены друг от друга пустой строкой\n",
        "* тексты токенизированы \n",
        "  * каждый токен находится на очередной строке\n",
        "  * каждому токену в соответствие поставлен тег в **BIO-нотации**.\n",
        "\n",
        "О **BIO-нотации** можно прочитать [тут](https://habr.com/ru/company/abbyy/blog/449514/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nXDOOQDCNoz"
      },
      "source": [
        "Наша модель должна уметь обработать предложение: сопоставить каждому токену предложения некоторую метку.\n",
        "\n",
        "Для упрощения дальнейшей работы давайте сразу считаем набор данных в переменные питона.\n",
        "Удобно иметь тренировочную запись, соответствующую каждому предложению, отделённой от записей, соответствующих другим предложениям.\n",
        "\n",
        "Организуем хранение наборов данных так: для набора данных будем иметь два списка -- список-про-тексты и список-про-теги. \n",
        "Каждый элемент такого списка &mdash; тоже список: список токенов или соответствующих тегов отдельного предложения. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yNQl1KVgbod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585d2fc2-9c5a-450d-b3f8-605939147b1d"
      },
      "source": [
        "def read_bio_dataset(dataset_fpath):\n",
        "    sentences_tokens, sentences_tags = [], []\n",
        "    curr_sent_tokens, curr_sent_tags = [], []\n",
        "\n",
        "    for line in open(dataset_fpath, encoding=\"utf-8\"):\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            sentences_tokens.append(curr_sent_tokens)\n",
        "            curr_sent_tokens = []\n",
        "            sentences_tags.append(curr_sent_tags)\n",
        "            curr_sent_tags = []\n",
        "        else:\n",
        "            curr_token, curr_tag = line.split('\\t')\n",
        "            curr_sent_tags.append(curr_tag)\n",
        "            curr_sent_tokens.append(curr_token)\n",
        "            \n",
        "    sentences_tokens.append(curr_sent_tokens)\n",
        "    sentences_tags.append(curr_sent_tags)\n",
        "\n",
        "    return sentences_tokens, sentences_tags\n",
        "\n",
        "\n",
        "train_sents_tokens, train_sents_tags = read_bio_dataset(TRAIN_DATA_FPATH)\n",
        "test_sents_tokens, test_sents_tags = read_bio_dataset(TEST_DATA_FPATH)\n",
        "\n",
        "print(f\"e.g. train sentences tokens:\\t{str(train_sents_tokens[10:12])}\")\n",
        "print(f\"e.g. train sentences tags:\\t{str(train_sents_tags[10:12])}\")\n",
        "print()\n",
        "print(f\"e.g. test sentences tokens:\\t{str(test_sents_tokens[10:12])}\")\n",
        "print(f\"e.g. test sentences tags:\\t{str(test_sents_tags[10:12])}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e.g. train sentences tokens:\t[['Fog', 'on', 'the', 'Essex', 'marshes', ',', 'fog', 'on', 'the', 'Kentish', 'heights', '.'], ['Fog', 'creeping', 'into', 'the', 'cabooses', 'of', 'collier-brigs', ';', 'fog', 'lying', 'out', 'on', 'the', 'yards', 'and', 'hovering', 'in', 'the', 'rigging', 'of', 'great', 'ships', ';', 'fog', 'drooping', 'on', 'the', 'gunwales', 'of', 'barges', 'and', 'small', 'boats', '.']]\n",
            "e.g. train sentences tags:\t[['O', 'O', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n",
            "\n",
            "e.g. test sentences tokens:\t[['These', 'customers', 'were', 'either', 'very', 'young', 'men', ',', 'who', 'hung', 'about', 'the', 'window', 'for', 'a', 'time', 'before', 'slipping', 'in', 'suddenly', ';', 'or', 'men', 'of', 'a', 'more', 'mature', 'age', ',', 'but', 'looking', 'generally', 'as', 'if', 'they', 'were', 'not', 'in', 'funds', '.'], ['Some', 'of', 'that', 'last', 'kind', 'had', 'the', 'collars', 'of', 'their', 'overcoats', 'turned', 'right', 'up', 'to', 'their', 'moustaches', ',', 'and', 'traces', 'of', 'mud', 'on', 'the', 'bottom', 'of', 'their', 'nether', 'garments', ',', 'which', 'had', 'the', 'appearance', 'of', 'being', 'much', 'worn', 'and', 'not', 'very', 'valuable', '.']]\n",
            "e.g. test sentences tags:\t[['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viL7wruCtqEK"
      },
      "source": [
        "Соберём вспомогательные переменные -- `vocab` (словарь) и `tagset` (набор тегов).\n",
        "Они нам потом пригодятся для того, чтобы представлять слова и теги при помощи чисел.\n",
        "\n",
        "Также чуть позже мы воспользуемся специальными токенами -- *паддингами* -- \n",
        "и при обработке текстовых цепочек, и при обработке цепочек тегов.   \n",
        "Сейчас заблаговременно запомним и эти паддинги."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoYOS9MucT7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629212af-e61f-4efe-9233-bb8a8cf968d6"
      },
      "source": [
        "PAD_TOKEN = \"PAD_TOKEN\"\n",
        "vocab = set(token \n",
        "            for sentence_tokens in train_sents_tokens+test_sents_tokens\n",
        "            for token in sentence_tokens)\n",
        "vocab.add(PAD_TOKEN)\n",
        "vocab = list(vocab)\n",
        "\n",
        "PAD_TAG = \"PAD_TAG\"\n",
        "tagset = set(tag\n",
        "            for sentence_tags in train_sents_tags+test_sents_tags\n",
        "            for tag in sentence_tags)\n",
        "tagset.add(PAD_TAG)\n",
        "tagset = list(tagset)\n",
        "\n",
        "\n",
        "print(f\"vocab size: {str(len(vocab))}, tagset_size: {str(len(tagset))}\")\n",
        "print(\"vocab samples:\", vocab[:5])\n",
        "print(\"tagset samples:\", tagset[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 4357, tagset_size: 8\n",
            "vocab samples: ['1810', 'boasted', 'bright', 'sought', 'Ghost']\n",
            "tagset samples: ['I-FAC', 'I-LOC', 'B-PER', 'O', 'B-LOC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0whx0AWbEkR_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d544f37f-bd18-4e45-fa17-97087e2a262a"
      },
      "source": [
        "sorted(tagset, \n",
        "       key=lambda x: ('-' in x,\n",
        "                      x.split('-', maxsplit=1)[-1], \n",
        "                      x.split('-', maxsplit=1)[0]),\n",
        "       reverse=False)\n",
        "# хитрая сортировка чтобы веселее жилось. \n",
        "# хочется посмотреть на то, какие есть теги, но так, чтобы они были по порядку."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'PAD_TAG', 'B-FAC', 'I-FAC', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2oFXSTwtu3q"
      },
      "source": [
        "Переменные `vocab` (словарь) и `tagset` (набор тегов) нам потом пригодятся для того, чтобы представлять слова и теги при помощи чисел. Давайте для удобства заранее заведём отображения элементов словаря\\тагсета на числа и обратно.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGgYUhHfdRGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797b900a-ab0a-4ef1-98f4-c424b46827f7"
      },
      "source": [
        "ix2word = dict(enumerate(vocab))\n",
        "word2ix = {w:ix for ix, w in ix2word.items()}\n",
        "\n",
        "ix2tag = dict(enumerate(tagset))\n",
        "tag2ix = {t:ix for ix, t in ix2tag.items()}\n",
        "\n",
        "print(\"word2ix samples:\", list(word2ix.items())[:5])\n",
        "print(\"tag2ix samples:\", list(tag2ix.items())[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word2ix samples: [('1810', 0), ('boasted', 1), ('bright', 2), ('sought', 3), ('Ghost', 4)]\n",
            "tag2ix samples: [('I-FAC', 0), ('I-LOC', 1), ('B-PER', 2), ('O', 3), ('B-LOC', 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C54_ws17wJFe"
      },
      "source": [
        "Теперь мы умеем превращать токены в числа.  \n",
        "Превратим обучающие последовательности (тексты и последовательности тегов) в последовательности чисел."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjKrvxVAetpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02edc10a-1d6b-402a-ebe8-349432f2f9a7"
      },
      "source": [
        "train_sents_digitized = [[word2ix[tok] for tok in sent_toks]\n",
        "                         for sent_toks in train_sents_tokens]\n",
        "\n",
        "test_sents_digitized = [[word2ix[tok] for tok in sent_toks]\n",
        "                         for sent_toks in test_sents_tokens]\n",
        "\n",
        "\n",
        "train_sent_tags_digitized = [[tag2ix[tag] for tag in sent_tags]\n",
        "                             for sent_tags in train_sents_tags]\n",
        "test_sent_tags_digitized = [[tag2ix[tag] for tag in sent_tags]\n",
        "                            for sent_tags in test_sents_tags]\n",
        "\n",
        "print(train_sents_digitized[10])\n",
        "print(train_sent_tags_digitized[10])\n",
        "print()\n",
        "print(test_sents_digitized[10])\n",
        "print(test_sent_tags_digitized[10])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2129, 4134, 1144, 1477, 3868, 2448, 3322, 4134, 1144, 3616, 3606, 4237]\n",
            "[3, 3, 3, 4, 1, 3, 3, 3, 3, 3, 3, 3]\n",
            "\n",
            "[3191, 2108, 3081, 2203, 1916, 1092, 2201, 2448, 1600, 4354, 736, 1144, 2084, 701, 3422, 1115, 1586, 2645, 3468, 1833, 4218, 3825, 2201, 756, 3422, 64, 2499, 1138, 2448, 3889, 4138, 645, 2812, 9, 3923, 3081, 248, 3468, 4046, 4237]\n",
            "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-loV5NLwr0L"
      },
      "source": [
        "Посмотрим, как теперь выглядит какой-то случайный обучающий пример."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nc72cnPsm0U4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "933965d2-899c-4a1e-e3c5-54035412f3b3"
      },
      "source": [
        "train_data = list(zip(train_sents_digitized, train_sent_tags_digitized))\n",
        "test_data = list(zip(test_sents_digitized, test_sent_tags_digitized))\n",
        "\n",
        "print(train_data[10])\n",
        "print()\n",
        "print(test_data[10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([2129, 4134, 1144, 1477, 3868, 2448, 3322, 4134, 1144, 3616, 3606, 4237], [3, 3, 3, 4, 1, 3, 3, 3, 3, 3, 3, 3])\n",
            "\n",
            "([3191, 2108, 3081, 2203, 1916, 1092, 2201, 2448, 1600, 4354, 736, 1144, 2084, 701, 3422, 1115, 1586, 2645, 3468, 1833, 4218, 3825, 2201, 756, 3422, 64, 2499, 1138, 2448, 3889, 4138, 645, 2812, 9, 3923, 3081, 248, 3468, 4046, 4237], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SlEr1yor-1J"
      },
      "source": [
        "Теперь это набор чисел, представляющих текст предложения и набор чисел, представляющих теги токенов этого текста. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XpdA5mvsPWT"
      },
      "source": [
        "##### О train, test, val подвыборках (subsamples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBsIfFaKbzwf"
      },
      "source": [
        "При обучении нейронной сети каждую эпоху происходит \n",
        "1. итерация обучения (forward+backward modes)\n",
        "2. итерация оценки (no backward)\n",
        "\n",
        "После обучения мы захотим оценить её на отложенных данных. \n",
        "Отложенный набор данных &mdash; это наш *test*, а ещё давайте откусим часть *train* для промежуточных оценок.\n",
        "Назовём эту часть данных *val*.\n",
        "\n",
        "Ещё на всякий случай перемешаем примеры из набора данных. \n",
        "`train_test_split` делает это по умолчанию, `shuffle` из `sklearn` тоже умеет перемешивать коллекции.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMTO2TKgkRFL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2)\n",
        "test_data = shuffle(test_data)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOFBzbGWb_Pg"
      },
      "source": [
        "Опять на всякий случай посмотрим на случайные примеры из *train*, *val*, *test*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PloYo3SbcGgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a593c36e-65ae-4a08-e8e6-ecc0d2eb7d08"
      },
      "source": [
        "print(train_data[10], \n",
        "      [ix2word[w_ix] for w_ix in train_data[10][0]], \n",
        "      [ix2tag[t_ix] for t_ix in train_data[10][1]],\n",
        "      sep='\\n', end='\\n***\\n')\n",
        "\n",
        "print(val_data[10], \n",
        "      [ix2word[w_ix] for w_ix in val_data[10][0]], \n",
        "      [ix2tag[t_ix] for t_ix in val_data[10][1]],\n",
        "      sep='\\n', end='\\n***\\n')\n",
        "\n",
        "print(test_data[10], \n",
        "      [ix2word[w_ix] for w_ix in test_data[10][0]], \n",
        "      [ix2tag[t_ix] for t_ix in test_data[10][1]],\n",
        "      sep='\\n', end='\\n***\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([2896, 2724, 3710, 3422, 3922, 1173, 2448, 1760, 3945, 3022, 2724, 1587, 924, 3922, 2052, 4237], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "['There', 'would', 'be', 'a', 'new', 'Ayah', ',', 'and', 'perhaps', 'she', 'would', 'know', 'some', 'new', 'stories', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "***\n",
            "([3620, 349, 2172, 2448, 3017, 148, 2448, 2675, 2724, 4139, 4181, 3858, 2847, 2246, 4047, 2448, 1831, 2675, 1706, 248, 285, 1916, 3260, 3835, 2378, 2007, 4237], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "['For', 'one', 'daughter', ',', 'his', 'eldest', ',', 'he', 'would', 'really', 'have', 'given', 'up', 'any', 'thing', ',', 'which', 'he', 'had', 'not', 'been', 'very', 'much', 'tempted', 'to', 'do', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "***\n",
            "([3976, 3081, 2100, 3468, 1144, 762, 46, 1760, 3415, 2811, 756, 1204, 177, 3333, 600, 4237], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "['They', 'were', 'apparent', 'in', 'the', 'extremely', 'neat', 'and', 'artistic', 'arrangement', 'of', 'her', 'glossy', 'dark', 'hair', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykDDruKCXcJV"
      },
      "source": [
        "## наивный бейзлайн"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1SHnq_EXf3V"
      },
      "source": [
        "Предположим, что если мы видим какое-то слово, то с ним сразу всё понятно.\n",
        "Например, про слово *Michael* понятно, что это имя.\n",
        "\n",
        "Давайте запомним, с каким тегом чаще всего встретилось каждое слово набора данных, и, встретив незнакомое предложение, протеггируем его следующим образом: встретив токен, припишем ему самый частый встретившийся рядом с этим токеном тег."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Fpwcq0Yc1w"
      },
      "source": [
        "Для каждого токена из обучающей выборки найдём самый частый соответствующий ему тег."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ir9kd8PYptR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45e591d7-24e3-4552-a5f9-02ec0020eb1f"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "token2tag2freq = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "for train_sentence in train_data:\n",
        "    tokens_ixes, tags_ixes = train_sentence[0], train_sentence[1]\n",
        "    tokens = [ix2word[tok_ix] for tok_ix in tokens_ixes]\n",
        "    tags = [ix2tag[tag_ix] for tag_ix in tags_ixes]\n",
        "    for token, tag in zip(tokens, tags):\n",
        "        token2tag2freq[token][tag] += 1\n",
        "\n",
        "token2most_frequent_tag = dict()\n",
        "for token, tag2freq in token2tag2freq.items():\n",
        "    token2most_frequent_tag[token] = max(tag2freq, key=lambda tag: tag2freq[tag])\n",
        "\n",
        "\n",
        "print(\"TOKEN\", \"MOST FREQUENT TAG\", sep='\\t')\n",
        "for token, most_frequent_tag in list(token2most_frequent_tag.items())[:5]:\n",
        "    print(token, most_frequent_tag, sep='\\t')\n",
        "print(\"...\", \"...\", sep='\\t')\n",
        "\n",
        "for token, most_frequent_tag in [(tok, tag) \n",
        "                                 for tok, tag in token2most_frequent_tag.items()\n",
        "                                 if tag != \"O\"][:5]:\n",
        "    print(token, most_frequent_tag, sep='\\t')\n",
        "print(\"...\", \"...\", sep='\\t')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKEN\tMOST FREQUENT TAG\n",
            "Horses\tO\n",
            ",\tO\n",
            "scarcely\tO\n",
            "better\tO\n",
            ";\tO\n",
            "...\t...\n",
            "Walter\tI-PER\n",
            "Esq.\tI-PER\n",
            "larger\tI-FAC\n",
            "rat-hole\tI-FAC\n",
            "John\tI-PER\n",
            "...\t...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A57oTTiGcBU0"
      },
      "source": [
        "Воспользуемся извлечённой информацией для теггирования отложенной тестовой выборки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4uZbb0CcApX"
      },
      "source": [
        "test_sentences_predictions = []\n",
        "for test_sentence in test_data:\n",
        "    tokens_ixes, tags_ixes = test_sentence[0], test_sentence[1]\n",
        "    tokens = [ix2word[tok_ix] for tok_ix in tokens_ixes]\n",
        "    tags = [ix2tag[tag_ix] for tag_ix in tags_ixes]\n",
        "\n",
        "    previous_tag = ''\n",
        "    predicted_tags = []\n",
        "    for token in tokens:\n",
        "        predicted_tag = token2most_frequent_tag.get(token, 'O')  # О для незнакомых слов\n",
        "        predicted_tags.append(predicted_tag)\n",
        "        previous_tag = predicted_tag\n",
        "    \n",
        "    predicted_tags_ixes = [tag2ix[tag] for tag in predicted_tags]\n",
        "    sentence_prediction = (tokens_ixes, predicted_tags_ixes)\n",
        "\n",
        "    test_sentences_predictions.append(sentence_prediction)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ui6ZJ30eefq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ed48f8-3d62-4f00-da41-4142e39dc7b1"
      },
      "source": [
        "print(test_sentences_predictions[0], \n",
        "      [ix2word[w_ix] for w_ix in test_sentences_predictions[0][0]], \n",
        "      [ix2tag[t_ix] for t_ix in test_sentences_predictions[0][1]],\n",
        "      sep='\\n', end='\\n***\\n')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([571, 3236, 2423, 2697, 4134, 1208, 3413, 3702, 348, 3995, 3422, 4091, 1760, 691, 2147, 4237], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n",
            "['It', 'was', 'only', 'later', 'on', 'that', 'Winnie', 'obtained', 'from', 'him', 'a', 'misty', 'and', 'confused', 'confession', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "***\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o1Uj5GBf_Oz"
      },
      "source": [
        "### оценка решения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3maXHWgVfIlF"
      },
      "source": [
        "Теперь, когда мы получили наивное решение, оценим её на тестовой выборке.\n",
        "\n",
        "Для наглядности, запомним предсказания модели, а также будем использовать две метрики оценки: среднее по примерам среднее качество на примере и среднее по примерам бинарное качество на примере.\n",
        "\n",
        "Среднее (`mean`) качество теггирования на входном тексте пропорционально количеству правильно теггированых токенов текста.\n",
        "Бинарное (`joint`) качество теггирования на входном тексте более строго: оно равно единице когда все токены теггированы правильно и равно нулю в всех остальных случаях. Таким образом, мы смотрим, правильно ли модель обработала пример или нет.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFO4RjK0whwR"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def binary_sentence_accuracy(sentence_predicted_tags, sentence_true_tags):\n",
        "    return int(sentence_predicted_tags == sentence_true_tags)\n",
        "\n",
        "def mean_sentence_accuracy(sentence_predicted_tags, sentence_true_tags):\n",
        "    sentence_len = len(sentence_predicted_tags)\n",
        "    equal_elems_num = sum(1 \n",
        "                          for tag_pred, tag_gold in zip(sentence_predicted_tags, \n",
        "                                                        sentence_true_tags)\n",
        "                          if tag_pred == tag_gold)\n",
        "    return equal_elems_num/sentence_len if sentence_len else 0\n",
        "\n",
        "def metrics(sentences_predictions, sentences_truths):\n",
        "    mean_accuracies = []\n",
        "    binary_accuracies = []\n",
        "    for sentence_predictions, sentence_truths in zip(sentences_predictions, sentences_truths):\n",
        "        assert sentence_predictions[0] == sentence_truths[0]\n",
        "        sentence_tokens = sentence_predictions[0]\n",
        "\n",
        "        sentence_tags_predicted_ixes = sentence_predictions[1]\n",
        "        sentence_tags_predicted = [ix2tag[tag_ix] for tag_ix in sentence_tags_predicted_ixes]\n",
        "\n",
        "        sentence_tags_true_ixes = sentence_truths[1]\n",
        "        sentence_tags_true = [ix2tag[tag_ix] for tag_ix in sentence_tags_true_ixes]\n",
        "\n",
        "        curr_sentence_mean_acc = mean_sentence_accuracy(sentence_tags_predicted, \n",
        "                                                        sentence_tags_true)\n",
        "        \n",
        "        curr_sentence_binary_acc = binary_sentence_accuracy(sentence_tags_predicted, \n",
        "                                                            sentence_tags_true)\n",
        "        \n",
        "        mean_accuracies.append(curr_sentence_mean_acc)\n",
        "        binary_accuracies.append(curr_sentence_binary_acc)\n",
        "    \n",
        "    mean_mean_accuracy = np.mean(mean_accuracies)\n",
        "    joint_accuracy = np.mean(binary_accuracies)\n",
        "\n",
        "    return {\"mean\": mean_mean_accuracy, \"joint\": joint_accuracy}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REl5b-sTwjQD"
      },
      "source": [
        "Посмотрим на метрики нашего решения"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBj-SNPugBVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd7784b2-a362-4ad6-a5be-bf74d604bf25"
      },
      "source": [
        "metrics(test_data, test_sentences_predictions)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'joint': 0.6144578313253012, 'mean': 0.9384193626120357}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npGdkzazLwAy"
      },
      "source": [
        "Скорее всего, лучше всего наша модель справляется с проставлением метки `O` всем словам в предложении: скорее всего для каждого слова метка `O` &mdash; самая частотная. В таком случае, joint метрику должны в первую очередь повышать случаи, когда в предложении на самом деле нет именованных сущностей. Модель предскажет метку `O` всем словам, и это окажется верным ответом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIqtvOmHXHty"
      },
      "source": [
        "## нейросетевой бейзлайн"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmTP5HroMV2X"
      },
      "source": [
        "Давайте теперь реализуем нейросетевой бейзлайн для нашей задачи. Его нужно будет превзойти, сдавая задание."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuiYAbwxXTCU"
      },
      "source": [
        "### группировка данных в батчи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsaIVP7IcG29"
      },
      "source": [
        "Современные вычислительные системы (нам особенно релевантны видеокарты) хороши тем, что способны за один момент времени совершить несколько подобных операций. Например, за один момент времени можно *(одновременно, параллельно)* посчитать значение одного и того же уравнения при нескольких разных входных переменных.\n",
        "\n",
        "Это используется для ускорения обучения нейронных сетей: при обучении приходится \n",
        "1. вычислить результаты работы нейронной сети для нескольких входных примеров\n",
        "2. по этим результатам оценить ошибку\n",
        "3. понимая ошибку, обновить нужные параметры нейронной сети.  \n",
        "\n",
        "Пункт *1.* кажется подходящим для описанного выше параллеллизма.\n",
        "\n",
        "\n",
        "Чтобы воспользоваться этим параллелизмом, **соберём наши обучающие примеры в группы - *батчи***, вычисления для каждого батча впоследствии будут происходить распараллеленно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hEN2uvVmmbI"
      },
      "source": [
        "def generate_batched_dataset(dataset, batch_size):\n",
        "\n",
        "    batched_dataset = []\n",
        "    curr_batch = []\n",
        "    for data_entry_idx, (src, tgt) in enumerate(dataset, 1):\n",
        "        curr_batch.append((src, tgt))\n",
        "        if data_entry_idx % batch_size == 0:\n",
        "            batched_dataset.append(list(zip(*curr_batch)))\n",
        "            curr_batch = []\n",
        "    batched_dataset.append(list(zip(*curr_batch)))\n",
        "\n",
        "    return batched_dataset\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "batched_train_data = generate_batched_dataset(train_data, BATCH_SIZE)\n",
        "batched_val_data = generate_batched_dataset(val_data, BATCH_SIZE)\n",
        "batched_test_data = generate_batched_dataset(test_data, BATCH_SIZE)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9iCVjfQeNZ3"
      },
      "source": [
        "Посмотрим на какой-то из полученных батчей. Это два набора: набор цифрованных предложений и набор соответствующих этим предложениям цепочек тегов (теги тоже цифрованы). \n",
        "\n",
        "Для проверки заметим, что длина каждого *i*-того по счёту в батче предложения совпадает с длиной соответствующей ему *i*-той по счёту в батче цепочки тегов. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST0IETNt1mtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae275e01-dd01-4efa-bc5f-18e5ae9a0a21"
      },
      "source": [
        "print(batched_test_data[-2])\n",
        "print(list(map(len, batched_test_data[-2][0])))\n",
        "print(list(map(len, batched_test_data[-2][1])))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[([120, 4137, 1942, 2910, 1144, 53, 589, 756, 396, 4237], [571, 1534, 3710, 1208, 120, 4137, 3236, 3445, 2378, 1569, 4209, 4237], [571, 1942, 3422, 3221, 756, 1144, 3041, 2448, 905, 1760, 1471, 2448, 1768, 2863, 3422, 1647, 3333, 3453, 1697, 3422, 1273, 1760, 1144, 4096, 756, 3422, 1938, 4237], [2555, 2556, 2675, 2849, 3468, 3864, 2177, 1208, 2675, 1706, 1933, 3422, 20, 3468, 3017, 732, 4237], [493, 3558, 1134, 1341, 3915, 3468, 1144, 2590, 3361, 756, 3558, 1405, 2448, 3923, 4216, 3468, 4130, 2448, 349, 3247, 113, 2448, 2812, 9, 1364, 2378, 764, 1144, 1427, 4230, 4237], [487, 2448, 2675, 3939, 1706, 2246, 125, 1381, 1831, 3236, 3891, 2779, 4218, 1760, 1586, 1144, 3452, 4114, 756, 1474, 4134, 1144, 3269, 756, 3017, 874, 2675, 3312, 3907, 2448, 3468, 3017, 3314, 1629, 710, 2448, 652, 701, 3676, 2518, 1144, 1651, 3829, 756, 3017, 2785, 3413, 4237], [2791, 2049, 3236, 64, 3867, 1715, 4237], [56, 2084, 1303, 183, 756, 64, 3825, 1737, 2036, 133, 850, 4218, 1231, 2742, 3468, 2597, 3206, 3914, 510, 4218, 1721, 3768, 1159, 597, 2448, 1916, 1266, 2448, 1760, 2033, 3287, 3468, 2409, 78, 1832, 4218, 3422, 4116, 2827, 756, 2318, 513, 2149, 516, 4354, 3514, 3422, 2178, 2812, 9, 2378, 3984, 4218, 3422, 945, 3602, 1619, 2293, 2448, 3422, 329, 756, 78, 3107, 2448, 4246, 756, 3423, 2859, 2448, 1760, 2121, 1879, 4218, 3422, 4116, 1369, 2448, 1697, 1699, 3278, 2261, 4208, 4218, 3422, 4116, 1446, 3330, 308, 756, 985, 2591, 2448, 4306, 1235, 2448, 1697, 1699, 3206, 3290, 56, 4184, 3290, 2448, 3290, 56, 1996, 3290, 1252, 4261, 1699, 4237], [1964, 2952, 2675, 1706, 3604, 662, 440, 246, 2910, 2448, 506, 1060, 1352, 2448, 1447, 1366, 2448, 1760, 731, 2670, 1489, 3017, 2133, 4237], [2510, 756, 1144, 513, 2939, 1831, 1144, 3338, 1, 756, 3081, 2100, 3468, 3413, 3085, 4237], [931, 3131, 1842, 1105, 3017, 2402, 1706, 3440, 1760, 3017, 2767, 1706, 4205, 3378, 662, 3700, 2448, 2090, 2448, 701, 1144, 113, 1115, 2594, 1204, 4066, 2448, 1204, 44, 2895, 701, 349, 2840, 506, 961, 1968, 853, 1204, 2338, 2764, 39, 4237], [3573, 2812, 4177, 2675, 2439, 248, 101, 2509, 3422, 1126, 1559, 4237], [1242, 1208, 22, 2363, 1656, 4112, 2378, 120, 4137, 2448, 1760, 2812, 3413, 2849, 506, 1167, 756, 4200, 1801, 3468, 1204, 4132, 2448, 3945, 3643, 3236, 2057, 2812, 2404, 701, 1709, 3248, 4237], [571, 2724, 4181, 285, 3085, 3260, 2289, 701, 120, 4137, 4237], [3057, 3468, 3017, 1951, 3153, 2388, 1706, 1808, 506, 229, 3453, 756, 3840, 2448, 436, 1448, 2448, 1600, 970, 3995, 349, 3578, 953, 1174, 1760, 506, 3383, 3933, 3462, 1144, 3231, 2507, 756, 2985, 140, 4237], [1465, 2928, 3017, 4018, 2090, 2675, 3236, 3930, 1105, 3330, 4237], [2791, 537, 3236, 3172, 2491, 2448, 1144, 4070, 1202, 2599, 1088, 2448, 1202, 1760, 1144, 448, 1020, 756, 1144, 353, 3236, 2448, 2261, 1144, 4350, 756, 3017, 1197, 2448, 95, 2106, 258, 2388, 4237], [1465, 769, 479, 3236, 756, 924, 907, 3468, 2981, 1204, 242, 4218, 3889, 1144, 4251, 756, 1144, 1230, 3338, 3081, 248, 2281, 756, 1144, 2019, 1485, 4237], [3573, 3017, 874, 1629, 3863, 2448, 756, 2435, 2448, 477, 3995, 279, 2812, 3989, 2378, 2062, 3017, 1741, 4237], [1128, 3017, 3986, 2448, 3961, 3017, 833, 2448, 3961, 3017, 482, 1518, 3081, 756, 1144, 1485, 2378, 3834, 3995, 3260, 171, 4237], [2622, 3413, 1629, 843, 1629, 1541, 120, 4137, 3236, 3422, 1916, 1799, 912, 4237], [2622, 1144, 3799, 1144, 2514, 3805, 1721, 4218, 3468, 1144, 3059, 4228, 1398, 1598, 3889, 1787, 3031, 4237], [3191, 380, 3081, 2024, 4237], [3729, 1706, 248, 285, 4048, 2378, 1976, 348, 1554, 1208, 2675, 3236, 3422, 1727, 3205, 2448, 1208, 1709, 3248, 4237], [56, 902, 1786, 3995, 3422, 2115, 4195, 1760, 1547, 4237], [3413, 4137, 3236, 3422, 1092, 144, 1697, 3422, 2220, 3727, 2448, 3468, 3422, 1254, 554, 2448, 1760, 1697, 742, 2656, 4237], [571, 3236, 2812, 3422, 156, 2378, 3017, 810, 3227, 1208, 2675, 1693, 1144, 775, 756, 1837, 3468, 2769, 3738, 4228, 4289, 3995, 4237], [2045, 1732, 1144, 167, 4237], [4178, 1804, 1725, 2530, 974, 2933, 2622, 2548, 2448, 1363, 2106, 2388, 3236, 1915, 2448, 877, 1105, 3081, 3454, 1566, 2594, 1346, 2448, 1144, 781, 4, 756, 3643, 2697, 2840, 2448, 1706, 2448, 1970, 2261, 3718, 2448, 2604, 408, 3995, 4237], [147, 4123, 2544, 2843, 1672, 1144, 2490, 3539, 4237], [2622, 3422, 2610, 2871, 756, 1144, 3496, 3684, 3260, 828, 4134, 1144, 845, 1629, 1510, 1760, 252, 3401, 4237], [145, 2378, 1144, 4254, 3276, 2448, 2675, 3604, 701, 3422, 4348, 1233, 1760, 2030, 3468, 3422, 3943, 39, 3468, 3861, 3476, 3738, 3422, 801, 3333, 1352, 756, 194, 2990, 1697, 3422, 1694, 1755, 863, 4237], [56, 1808, 4097, 1589, 1204, 853, 1697, 1144, 2587, 4237], [2791, 855, 701, 3643, 991, 756, 3519, 3081, 1483, 2378, 573, 4237], [2791, 2526, 3081, 2928, 4237], [571, 3236, 3806, 756, 3995, 1208, 1706, 2675, 248, 532, 2378, 3116, 2273, 1092, 2675, 2164, 4181, 1202, 1347, 762, 2404, 4237, 1202], [2791, 941, 756, 1144, 4070, 2599, 1088, 3081, 2145, 1760, 3218, 4237], [56, 2514, 756, 1144, 1800, 3236, 1144, 2423, 3306, 756, 3734, 2378, 1144, 4012, 3468, 1831, 120, 4137, 484, 4134, 3017, 1741, 756, 3422, 845, 756, 4273, 2667, 2448, 2964, 3017, 1631, 756, 3422, 2534, 756, 2386, 2448, 1760, 2563, 3017, 3903, 4143, 4237], [3967, 2378, 2106, 2170, 3236, 3422, 2132, 936, 3178, 2448, 1208, 1493, 2261, 327, 1397, 4237], [120, 4137, 3236, 506, 476, 1005, 4237], [3413, 1706, 721, 903, 4147, 2351, 1204, 3897, 4218, 1204, 2220, 2448, 3936, 1299, 4218, 1204, 2881, 3819, 4218, 1144, 1978, 756, 1204, 3138, 646, 2448, 1831, 3939, 4076, 2273, 1383, 2812, 2378, 2903, 3490, 2448, 484, 4134, 4134, 1144, 396, 1615, 3269, 1697, 1413, 2448, 1760, 4134, 2506, 1697, 506, 468, 2467, 4237], [3071, 1144, 2162, 756, 1072, 3528, 1105, 2724, 709, 1833, 2936, 2261, 3127, 2378, 2054, 1697, 3422, 144, 2448, 1760, 1697, 4175, 3468, 3017, 1417, 2724, 3842, 3422, 4350, 701, 3422, 430, 756, 3423, 2859, 2448, 3496, 2574, 1880, 1381, 955, 3468, 4137, 1629, 1800, 3587, 2779, 2448, 1831, 2448, 1680, 2711, 2448, 2675, 2724, 2023, 2465, 3462, 1144, 3286, 4237], [1691, 3172, 2491, 2388, 1706, 1202, 1486, 3531, 1521, 2448, 1202, 2812, 1204, 2316, 310, 1150, 348, 1115, 2378, 1115, 2448, 874, 1760, 2613, 3604, 2847, 2261, 2948, 4231, 3468, 2839, 2448, 1760, 1232, 3404, 2630, 2378, 2106, 4231, 1168, 1760, 633, 3237, 2448, 3170, 3713, 701, 3060, 2812, 3260, 2812, 506, 720, 4237], [2045, 3236, 2889, 2712, 2106, 2995, 3883, 1760, 3707, 3883, 1760, 4079, 2378, 3349, 1949, 2448, 1202, 478, 2448, 924, 1115, 1472, 4195, 1202, 4218, 3889, 2209, 756, 1344, 993, 4063, 4237], [2791, 4027, 2448, 2195, 1144, 4001, 756, 1208, 788, 4146, 1831, 4331, 2248, 4134, 2124, 3889, 1144, 4116, 2448, 1623, 580, 2847, 3063, 2378, 327, 1419, 756, 1144, 1138, 4237], [2045, 968, 506, 570, 3221, 2448, 1872, 3422, 3920, 1925, 3032, 756, 280, 1928, 2448, 4349, 551, 2448, 1760, 3745, 3085, 3522, 2378, 3968, 4218, 3468, 3643, 2738, 1886, 2675, 2724, 2486, 1586, 3422, 3838, 3468, 3017, 39, 3825, 773, 1374, 3468, 3999, 4327, 3017, 1743, 4138, 3103, 4134, 1144, 3951, 1760, 564, 659, 3643, 4347, 2448, 3533, 1760, 3987, 2448, 3468, 1831, 4228, 2363, 2675, 3236, 3939, 2378, 4181, 3422, 3269, 4237], [3573, 1363, 2675, 4076, 2509, 2675, 2363, 2378, 2371, 3422, 1126, 1055, 3468, 4017, 3017, 1803, 3099, 2378, 3017, 1048, 4083, 3468, 1144, 295, 411, 4237], [74, 2675, 4076, 2378, 3337, 2448, 1144, 258, 2071, 2509, 756, 3017, 4293, 2378, 3422, 3405, 3880, 756, 2855, 1760, 3236, 3939, 2445, 756, 687, 4237], [2045, 2849, 2261, 4083, 1144, 1815, 756, 3017, 1494, 1760, 1144, 2913, 756, 3017, 4015, 2448, 1286, 1697, 1358, 4137, 1629, 4206, 921, 1760, 1358, 4137, 1629, 843, 1629, 1934, 3280, 4237], [2045, 3404, 1760, 4076, 2413, 2246, 1916, 2100, 2166, 4237], [1465, 3236, 2106, 2261, 3589, 2448, 1144, 2177, 756, 3017, 843, 4231, 3178, 4237], [2045, 645, 3605, 3468, 231, 1381, 3206, 1144, 1422, 2779, 348, 1144, 1753, 2448, 2423, 2675, 3605, 932, 1489, 1144, 2698, 4218, 1760, 3017, 989, 1153, 3468, 1697, 1126, 940, 4237], [571, 3581, 1208, 877, 903, 2424, 3468, 1144, 3539, 1706, 3546, 408, 3017, 2179, 1489, 1431, 756, 1687, 1760, 3323, 3942, 3923, 1706, 369, 3017, 3193, 2378, 1144, 1263, 756, 1208, 910, 4237], [3436, 4074, 3923, 2439, 3834, 4218, 1363, 2106, 3236, 617, 3923, 4076, 171, 2448, 2378, 1607, 1760, 4054, 2448, 1760, 1535, 3468, 1144, 650, 752, 3468, 1524, 3017, 874, 3440, 1697, 3260, 911, 1760, 119, 1760, 3473, 603, 701, 2333, 4237], [1465, 1343, 3995, 3889, 1595, 3129, 3995, 3738, 2675, 2315, 4230, 2509, 2448, 2261, 113, 3422, 264, 1760, 1547, 3422, 1126, 2054, 4237], [3729, 2724, 4181, 2448, 2675, 4292, 1204, 2448, 2378, 3710, 1916, 1799, 2378, 3017, 1255, 2704, 4237], [1082, 1144, 1271, 756, 758, 3784, 3643, 138, 3236, 4088, 1437, 701, 2249, 4168, 2448, 3889, 2812, 4228, 1742, 1887, 3017, 3178, 2378, 3710, 1249, 3190, 1760, 60, 986, 2448, 4228, 3939, 3702, 3997, 3422, 2342, 3466, 4237], [2045, 1003, 758, 158, 475, 3536, 1697, 3671, 3429, 2448, 3889, 2448, 2124, 1144, 3364, 2448, 3805, 2509, 3942, 1144, 995, 3236, 1383, 2336, 4237], [2896, 3236, 629, 1154, 3297, 3468, 785, 138, 4237], [2080, 824, 4193, 2570, 3995, 2378, 3332, 2378, 1144, 3493, 756, 3898, 4237], [3150, 32, 2313, 51, 1952, 259, 1964, 617, 2675, 1706, 3422, 610, 756, 3178, 4237], [2791, 1879, 3081, 3017, 1864, 3308, 1760, 2675, 4008, 1667, 1219, 4134, 2246, 349, 1600, 3772, 3995, 2261, 1983, 1697, 1344, 4218, 3923, 942, 3017, 2049, 327, 4173, 2448, 1760, 2675, 3255, 3785, 2261, 995, 1073, 3155, 4134, 3558, 3543, 1760, 1882, 1622, 4237], [56, 2177, 3468, 1831, 3643, 2463, 4158, 2849, 3995, 1089, 4218, 3017, 4021, 1706, 281, 952, 4218, 3376, 3236, 3561, 2847, 1788, 4134, 2292, 4218, 3017, 976, 3437, 3422, 1126, 2054, 4134, 1144, 542, 2853, 2448, 1191, 4134, 3017, 2479, 537, 1760, 2613, 2448, 662, 4103, 4134, 3017, 2831, 2106, 4237], [56, 1800, 3236, 3422, 411, 1354, 756, 3422, 963, 2448, 1697, 1144, 1531, 3460, 3468, 3801, 4092, 4237]), ([2, 7, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 2, 7, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 2, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 2, 7, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 7, 7, 7, 7, 7, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 2, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3], [3, 2, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 2, 7, 7, 3, 3, 2, 7, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 2, 7, 7, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [2, 7, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 0, 0, 0, 3, 3, 3, 3, 3, 3, 5, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 0, 0, 0, 0, 0, 0, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 7, 3, 3, 3, 3, 2, 7, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 2, 7, 7, 7, 7, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])]\n",
            "[10, 12, 28, 17, 31, 48, 7, 112, 24, 16, 42, 12, 33, 11, 36, 11, 34, 27, 19, 22, 14, 18, 5, 20, 10, 21, 23, 5, 41, 9, 19, 35, 10, 12, 5, 23, 12, 44, 16, 7, 54, 61, 54, 32, 30, 73, 26, 26, 32, 10, 14, 31, 33, 41, 23, 17, 38, 25, 9, 13, 15, 44, 51, 18]\n",
            "[10, 12, 28, 17, 31, 48, 7, 112, 24, 16, 42, 12, 33, 11, 36, 11, 34, 27, 19, 22, 14, 18, 5, 20, 10, 21, 23, 5, 41, 9, 19, 35, 10, 12, 5, 23, 12, 44, 16, 7, 54, 61, 54, 32, 30, 73, 26, 26, 32, 10, 14, 31, 33, 41, 23, 17, 38, 25, 9, 13, 15, 44, 51, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVnpNdRYeP4x"
      },
      "source": [
        "Стоит помнить, что в каждом батче у нас набор последовательностей, для которых мы будем проводить вычисления. Батч &mdash; это набор подобных друг другу элементов, благодаря подобности которых становится возможным одновременно вычислить что-то для каждого из элементов батча.\n",
        "\n",
        "В нашем батче все **последовательности имеют разную длину**. \n",
        "Это нарушает идею о подобности элементов батча. \n",
        "Давайте элементы в каждом батче уподобим по длине, добавив к каждой последовательности специальный \"хвост\" из элементов &mdash; символов паддинга:\n",
        "\n",
        "```\n",
        "[[a, b, c], \n",
        " [d, e], \n",
        " [f]] \n",
        "\n",
        "превращается в \n",
        "\n",
        "[[a,   b,   c], \n",
        " [d,   e, PAD], \n",
        " [f, PAD, PAD]] \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0imr4X0hfqLm"
      },
      "source": [
        "def pad_batch_of_sequences(batch_sequences, padding_elem):\n",
        "    longest_sequence_len = max([len(seq) for seq in batch_sequences])\n",
        "    padded_sequence_len = longest_sequence_len #+ #1  # [последо, ватель, .., ность, (PAD, PAD,..)]\n",
        "    padded_sequences = [seq + [padding_elem]*(padded_sequence_len - len(seq))\n",
        "                        for seq in batch_sequences]\n",
        "    \n",
        "    return(padded_sequences)\n",
        "\n",
        "def pad_batched_dataset_of_sequences_pairs(dataset_of_sequences_pairs,\n",
        "                                           src_seq_pad_elem,\n",
        "                                           tgt_seq_pad_elem):\n",
        "    padded_dataset = [(pad_batch_of_sequences(src_seq, src_seq_pad_elem),\n",
        "                       pad_batch_of_sequences(tgt_seq, tgt_seq_pad_elem))\n",
        "                      for src_seq, tgt_seq in dataset_of_sequences_pairs]\n",
        "    return padded_dataset\n",
        "\n",
        "\n",
        "padded_batched_train_data = pad_batched_dataset_of_sequences_pairs(batched_train_data, \n",
        "                                                                   word2ix[PAD_TOKEN],\n",
        "                                                                   tag2ix[PAD_TAG])\n",
        "\n",
        "padded_batched_val_data = pad_batched_dataset_of_sequences_pairs(batched_val_data, \n",
        "                                                                 word2ix[PAD_TOKEN],\n",
        "                                                                 tag2ix[PAD_TAG])\n",
        "\n",
        "padded_batched_test_data = pad_batched_dataset_of_sequences_pairs(batched_test_data, \n",
        "                                                                  word2ix[PAD_TOKEN],\n",
        "                                                                  tag2ix[PAD_TAG]) \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JqV_HNfelVV"
      },
      "source": [
        "### описание нейронной сети и сопутствующего"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlsUGZy67Z-Y"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKZef7BZxgXm"
      },
      "source": [
        "# в переменной DEVICE запомнится полезная информация о видеокарте в нашей системе\n",
        "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlfMttFgjqNV"
      },
      "source": [
        "Тренировка нейросети на наборе данных и оценка нейросети на наборе данных похожи. Единственное различие -- при тренировке мы используем оценку ошибки для обновления весов нейросети.\n",
        "\n",
        "В pytorch если мы не планируем в ближайшие запуски обновлять веса нейросети, стоит перевести её в положение `eval`. Если планируем &mdash; в положение `test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxoQuB3AtWr7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def batch_preds_aggregated_loss(pred_tgt, gold_tgt, criterion):\n",
        "\n",
        "    batch_size = gold_tgt.shape[0]\n",
        "    seq_len = gold_tgt.shape[1]\n",
        "\n",
        "    batch_elems_losses = torch.mean(\n",
        "        torch.stack([criterion(pred_tgt.view(batch_size, seq_len, -1)[batch_entry_idx],\n",
        "                               gold_tgt.view(batch_size, seq_len)[batch_entry_idx])\n",
        "                             for batch_entry_idx in range(batch_size)]))\n",
        "    aggregated_loss = batch_elems_losses.mean()\n",
        "    return aggregated_loss\n",
        "\n",
        "def epoch_iter(model, batched_dataset, optimizer, criterion, update_weights):\n",
        "    if update_weights:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    \n",
        "    iter_losses = []\n",
        "\n",
        "    for src, tgt in batched_dataset:\n",
        "        src_tensor = torch.tensor(src).to(DEVICE)\n",
        "        tgt_tensor = torch.tensor(tgt).to(DEVICE)\n",
        "\n",
        "        output, _ = model(src_tensor)\n",
        "\n",
        "        batch_loss = batch_preds_aggregated_loss(output, tgt_tensor, criterion)\n",
        "        \n",
        "        if update_weights:\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        iter_losses.append(batch_loss.item())\n",
        "    \n",
        "    return np.mean(iter_losses)\n",
        "\n",
        "\n",
        "def train_epoch(model, batched_dataset, optimizer, criterion):\n",
        "    return epoch_iter(model, batched_dataset, optimizer, criterion, update_weights=True)\n",
        "\n",
        "def test_epoch(model, batched_dataset, optimizer, criterion):\n",
        "    return epoch_iter(model, batched_dataset, optimizer, criterion, update_weights=False)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYmozT2j6M4U"
      },
      "source": [
        "### запуск обучения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tr3GN6bZerDU"
      },
      "source": [
        "Опишем простую нейронную сеть на фреймворке pytorch.\n",
        "\n",
        "Для теггирования последовательностей наивным бейзлайном можно считать однослойную LSTM-сеть.\n",
        "\n",
        "Элементы последовательности попадают в LSTM-сеть через выучиваемый линейный слой (эмбеддингов). \n",
        "\n",
        "Выход LSTM-сети отображается на множество тегов ещё одним линейным слоем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0bb8-5Woxln"
      },
      "source": [
        "class LSTMModel(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, output_dim,\n",
        "                 emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = torch.nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = torch.nn.LSTM(emb_dim, hidden_dim, bidirectional=True)\n",
        "        self.fc = torch.nn.Linear(2*hidden_dim, output_dim)\n",
        "    \n",
        "    def forward(self, in_seqs_batch):\n",
        "        embedded = self.emb(in_seqs_batch)\n",
        "        lstm_out, hc = self.lstm(embedded)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out, hc"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY5I29NNmlE2"
      },
      "source": [
        "Архитектура нашей сети такова: на вход модели подаётся вектор, он линейным слоем эмбеддингов отображается в некоторый другой вектор-эмбеддинг, эмбеддинг подаётся в LSTM-слой, выход LSTM-слоя отображается в некоторый вектор, являющийся выходным вектором всей нейросети.\n",
        "\n",
        "Мы можем конфигурировать размерность векторов эмбеддингов и размерность слоя LSTM. Входные и выходные векторы &mdash; это наши слова и теги соответственно, и их размерности предопределены и равны размеру словаря и тагсета.\n",
        "\n",
        "При работе с паддингами, можно помнить, что занятая паддингами часть цепочки токенов -- это наше техническое дополнение, не имеющее смысловой интерпретации в мире исходной задачи. Не стоит штрафовать модель за ошибки в работе с паддингами, такие ошибки всё равно находятся за границей осмысленной части текста, будем их игнорировать.\n",
        "\n",
        "Стоит также помнить, что иногда в вычислениях мы опираемся на техническую переменную `device`, помогающую pytorch понять, есть ли шанс воспользоваться видеокартой в вычислениях."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTMModel"
      ],
      "metadata": {
        "id": "LJ6NsHgxeFk5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mESkAEjWmz7H"
      },
      "source": [
        "Теперь, когда мы обучили модель, проверим работает ли она: оценим её на тестовой выборке.\n",
        "\n",
        "Для наглядности, запомним предсказания модели, а также будем использовать две метрики оценки: среднее по примерам среднее качество на примере и среднее по примерам бинарное качество на примере.\n",
        "\n",
        "Среднее (`mean`) качество теггирования на входном тексте пропорционально количеству правильно теггированых токенов текста.\n",
        "Бинарное (`joint`) качество теггирования на входном тексте более строго: оно равно единице когда все токены теггированы правильно и равно нулю в всех остальных случаях. Таким образом, мы смотрим, правильно ли модель обработала пример или нет.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZK6hcv1zVQU"
      },
      "source": [
        "def batch_score(src_tensor, tgt_tensor):\n",
        "    \"\"\"returns mean and joint scores on data batch\"\"\"\n",
        "    src = src_tensor.tolist()\n",
        "    tgt = tgt_tensor.tolist()\n",
        "\n",
        "    pred, _ = model(src_tensor)  # получаем предсказания модели на элементах батча\n",
        "    \n",
        "    batch_tok2tag2pred = []\n",
        "    batch_joint_accuracies = []\n",
        "    batch_mean_accuracies = []\n",
        "    for some_src, some_tgt, tags_predicted_digitized in zip(src, \n",
        "                                                            tgt, \n",
        "                                                            pred.argmax(dim=-1).tolist()):\n",
        "        # восстанавливаем токены, предсказанные и ожидаемые метки токенов, из их численных записей\n",
        "        tokens = list(map(ix2word.get, some_src))\n",
        "        tags_true = list(map(ix2tag.get, some_tgt))\n",
        "        tags_pred = list(map(ix2tag.get, tags_predicted_digitized))\n",
        "\n",
        "        tok2tag2pred = list(zip(tokens, tags_true, tags_pred))\n",
        "        \n",
        "        batch_tok2tag2pred.append(tok2tag2pred)\n",
        "\n",
        "        correct_preds = []  # чтобы хранить верные предсказания модели в человекочитаемом виде\n",
        "        actual_preds = []  # чтобы хранить *все* предсказания модели в человекочитаемом виде\n",
        "        for tok, gold_tag, pred_tag in tok2tag2pred:\n",
        "            if gold_tag == PAD_TAG:\n",
        "                # нас не волнуют ошибки на паддингах, тк они находятся за пределами предложения\n",
        "                break\n",
        "\n",
        "            batch_entry_w_prediction = (tok, gold_tag, pred_tag)\n",
        "            if gold_tag == pred_tag:\n",
        "                correct_preds.append(batch_entry_w_prediction)\n",
        "            actual_preds.append(batch_entry_w_prediction)\n",
        "\n",
        "        correct_preds_num = len(correct_preds)\n",
        "        joint_accuracy = int(correct_preds_num == len(actual_preds))  # 1 если не было ошибок, иначе 0\n",
        "        mean_accuracy = correct_preds_num/len(actual_preds) if actual_preds else 0  # доля верных ответов\n",
        "        batch_joint_accuracies.append(joint_accuracy)\n",
        "        batch_mean_accuracies.append(mean_accuracy)\n",
        "\n",
        "\n",
        "    return batch_tok2tag2pred, batch_joint_accuracies, batch_mean_accuracies\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDNeYO9Amtoo"
      },
      "source": [
        "Будем учить модель несколько эпох. На каждой эпохе будем обращать внимание на ошибку на валидационной выборке: именно она информативно характеризует, обучилась ли модель.\n",
        "\n",
        "Если валидационная ошибка не будет уменьшаться на протяжении длительного времени, остановим обучение модели, тк оно уже не приводит к наблюдаемым улучшениям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGN49qHzyCJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "3d938fbd-9de8-4a9b-ebf5-d01ca4319920"
      },
      "source": [
        "'''\n",
        "model = LSTMModel(len(word2ix), len(tag2ix), emb_dim=100, hidden_dim=100)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=tag2ix[PAD_TAG])\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "criterion = criterion.to(DEVICE)\n",
        "\n",
        "\n",
        "EPOCHS = 100\n",
        "IMPATIENCE_LIMIT = 5\n",
        "\n",
        "val_losses = [float(\"inf\")] * (IMPATIENCE_LIMIT + 1)\n",
        "for epoch_num in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, padded_batched_train_data, optimizer, criterion)\n",
        "    val_loss = test_epoch(model, padded_batched_val_data, optimizer, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    increasing_val_losses_tail_len = 0\n",
        "    for loss in val_losses[-IMPATIENCE_LIMIT:]:\n",
        "        if loss > val_losses[-IMPATIENCE_LIMIT-1]:\n",
        "            increasing_val_losses_tail_len += 1\n",
        "\n",
        "    print(f\"epoch {epoch_num}\", \n",
        "          f\"train loss {train_loss}\",\n",
        "          f\"val loss {val_loss}\",\n",
        "          f\"impatience {increasing_val_losses_tail_len} of {IMPATIENCE_LIMIT}\",\n",
        "          sep='\\t')\n",
        "\n",
        "    if increasing_val_losses_tail_len >= IMPATIENCE_LIMIT:\n",
        "        print(\"impatience stop in epoch\", epoch_num)\n",
        "        break\n",
        "'''"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = LSTMModel(len(word2ix), len(tag2ix), emb_dim=100, hidden_dim=100)\\n\\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=tag2ix[PAD_TAG])\\nmodel = model.to(DEVICE)\\noptimizer = torch.optim.Adam(params=model.parameters())\\ncriterion = criterion.to(DEVICE)\\n\\n\\nEPOCHS = 100\\nIMPATIENCE_LIMIT = 5\\n\\nval_losses = [float(\"inf\")] * (IMPATIENCE_LIMIT + 1)\\nfor epoch_num in range(EPOCHS):\\n    train_loss = train_epoch(model, padded_batched_train_data, optimizer, criterion)\\n    val_loss = test_epoch(model, padded_batched_val_data, optimizer, criterion)\\n    val_losses.append(val_loss)\\n\\n    increasing_val_losses_tail_len = 0\\n    for loss in val_losses[-IMPATIENCE_LIMIT:]:\\n        if loss > val_losses[-IMPATIENCE_LIMIT-1]:\\n            increasing_val_losses_tail_len += 1\\n\\n    print(f\"epoch {epoch_num}\", \\n          f\"train loss {train_loss}\",\\n          f\"val loss {val_loss}\",\\n          f\"impatience {increasing_val_losses_tail_len} of {IMPATIENCE_LIMIT}\",\\n          sep=\\'\\t\\')\\n\\n    if increasing_val_losses_tail_len >= IMPATIENCE_LIMIT:\\n        print(\"impatience stop in epoch\", epoch_num)\\n        break\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01cRG1UZf0_q"
      },
      "source": [
        "### оценка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suz2P9Zi9NgC"
      },
      "source": [
        "Выберем случайное предложение из тестовой выборки, посмотрим на предсказание тегов для него моделью."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw7wsYZ3HyMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1f7f3612-75e7-4f54-fd27-74b12937e280"
      },
      "source": [
        "'''\n",
        "import random\n",
        "\n",
        "# давайте возьмём случайный батч данных\n",
        "some_batch_src, some_batch_tgt = batched_train_data[random.randrange(0, len(batched_train_data))]\n",
        "some_batch_src2tgt = list(zip(some_batch_src, some_batch_tgt))\n",
        "\n",
        "# давайте возьмём случайный элемент из выбранного батча\n",
        "some_src, some_tgt = some_batch_src2tgt[random.randrange(0, len(some_batch_src2tgt))]\n",
        "print(some_src, some_tgt)\n",
        "\n",
        "\n",
        "src_tensor = torch.LongTensor([some_src]).to(DEVICE)  # тривиальный батч из выбранного эл-та\n",
        "tgt_tensor = torch.LongTensor([some_tgt]).to(DEVICE)  # тривиальный батч из выбранного эл-та\n",
        "model_results, joint_scores, mean_scores = batch_score(src_tensor, tgt_tensor)\n",
        "\n",
        "print(f\"mean accuracy:\\t{mean_scores[0]}\", \n",
        "      f\"joint accuracy:\\t{joint_scores[0]}\",\n",
        "      '*' * 3,\n",
        "      sep='\\n')\n",
        "import pandas as pd\n",
        "pd.DataFrame(model_results[0], \n",
        "             columns=[\"token\", \"gold tag\", \"pred tag\"])\n",
        "'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport random\\n\\n# давайте возьмём случайный батч данных\\nsome_batch_src, some_batch_tgt = batched_train_data[random.randrange(0, len(batched_train_data))]\\nsome_batch_src2tgt = list(zip(some_batch_src, some_batch_tgt))\\n\\n# давайте возьмём случайный элемент из выбранного батча\\nsome_src, some_tgt = some_batch_src2tgt[random.randrange(0, len(some_batch_src2tgt))]\\nprint(some_src, some_tgt)\\n\\n\\nsrc_tensor = torch.LongTensor([some_src]).to(DEVICE)  # тривиальный батч из выбранного эл-та\\ntgt_tensor = torch.LongTensor([some_tgt]).to(DEVICE)  # тривиальный батч из выбранного эл-та\\nmodel_results, joint_scores, mean_scores = batch_score(src_tensor, tgt_tensor)\\n\\nprint(f\"mean accuracy:\\t{mean_scores[0]}\", \\n      f\"joint accuracy:\\t{joint_scores[0]}\",\\n      \\'*\\' * 3,\\n      sep=\\'\\n\\')\\nimport pandas as pd\\npd.DataFrame(model_results[0], \\n             columns=[\"token\", \"gold tag\", \"pred tag\"])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXQtdIdF-DT7"
      },
      "source": [
        "Посчитаем наши `mean` и `join` метрики на всей тестовой выборке, перебрав все батчи. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJSbhy5oH7kX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4a11a264-eaa7-4709-8c89-f035a03f8b9d"
      },
      "source": [
        "'''\n",
        "joint_accuracies = []\n",
        "mean_accuracies = []\n",
        "for src, tgt in padded_batched_test_data:\n",
        "    src_tensor = torch.LongTensor(src).to(DEVICE)\n",
        "    tgt_tensor = torch.LongTensor(tgt).to(DEVICE)\n",
        "\n",
        "    t2t2t, joints, means = batch_score(src_tensor, tgt_tensor)\n",
        "    joint_accuracies.extend(joints)\n",
        "    mean_accuracies.extend(means)\n",
        "# Посмотрим среднее значение mean и join метрик на элементах тестовой выборки\n",
        "{\"joint\": np.mean(joint_accuracies), \n",
        " \"mean\": np.mean(mean_accuracies)}\n",
        "'''"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\njoint_accuracies = []\\nmean_accuracies = []\\nfor src, tgt in padded_batched_test_data:\\n    src_tensor = torch.LongTensor(src).to(DEVICE)\\n    tgt_tensor = torch.LongTensor(tgt).to(DEVICE)\\n\\n    t2t2t, joints, means = batch_score(src_tensor, tgt_tensor)\\n    joint_accuracies.extend(joints)\\n    mean_accuracies.extend(means)\\n# Посмотрим среднее значение mean и join метрик на элементах тестовой выборки\\n{\"joint\": np.mean(joint_accuracies), \\n \"mean\": np.mean(mean_accuracies)}\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8fPFPND-TUp"
      },
      "source": [
        "Модель ошибается на примерно пятой части токенов, а верно теггированы целиком примерно пятая часть предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwKXPmqkmIaw"
      },
      "source": [
        "# Секция для решения домашнего задания."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68ojl5IhMyxR"
      },
      "source": [
        "Выше в тетради представлены два бейзлайна для решения задачи классификации. Мы оценивали эти бейзлайны на отложенной выборке.\n",
        "Мы (организаторы курса) также отложили ещё один кусок выборки и оценили бейзлайны на нём.\n",
        "\n",
        "**Ваша задача** &mdash; написать нейросетевую модель, результат работы которой превзойдёт реализованные выше бейзлайны.\n",
        "\n",
        "### Формат сдачи задания\n",
        "Отправить на проверку ваше решение предстоит следующим образом: \n",
        "* нужно вашей моделью предсказать теги для проверочной выборки, \n",
        "* в форме для сдачи задания прикрепить два файла:\n",
        "  1. файл с предсказанием вашей модели на проверочной выборке (назовите файл так, чтобы его расширение было `.bio`) \n",
        "  2. zip-архив с кодом, в котором описана ваша модель и то, как она обучается."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "69g5bwRYei0A"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 16ZylRqsmwBIOtuLC9hqmIIhfHdGX7hI3\n",
        "\n",
        "df_test = pd.read_csv('/content/assignment_test_sample_solution.tsv', sep='\\t')\n",
        "df_test.head(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rDmHB_wqxwWI",
        "outputId": "89eb0e54-afd5-4f5e-d0af-bed674d577c9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16ZylRqsmwBIOtuLC9hqmIIhfHdGX7hI3\n",
            "To: /content/assignment_test_sample_solution.tsv\n",
            "100% 153k/153k [00:00<00:00, 72.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         PART      O\n",
              "0          I.  B-GPE\n",
              "1     FRIENDS      O\n",
              "2          OF      O\n",
              "3   CHILDHOOD  I-PER\n",
              "4           I      O\n",
              "5         Dr.  B-GPE\n",
              "6      Howard      O\n",
              "7      Archie      O\n",
              "8         had      O\n",
              "9        just      O\n",
              "10       come      O\n",
              "11         up      O\n",
              "12       from      O\n",
              "13          a  I-LOC\n",
              "14       game      O\n",
              "15         of      O\n",
              "16       pool      O\n",
              "17       with      O\n",
              "18        the      O\n",
              "19     Jewish      O\n",
              "20   clothier  B-PER\n",
              "21        and      O\n",
              "22        two      O\n",
              "23  traveling      O\n",
              "24        men      O\n",
              "25        who      O\n",
              "26   happened      O\n",
              "27         to      O\n",
              "28         be      O\n",
              "29    staying      O\n",
              "30  overnight      O\n",
              "31         in      O\n",
              "32  Moonstone      O\n",
              "33          .  B-GPE\n",
              "34        His      O\n",
              "35    offices      O\n",
              "36       were      O\n",
              "37         in      O\n",
              "38        the      O\n",
              "39       Duke      O\n",
              "40      Block      O\n",
              "41          ,      O\n",
              "42       over  B-PER\n",
              "43        the      O\n",
              "44       drug      O\n",
              "45      store      O\n",
              "46          .  B-GPE\n",
              "47      Larry      O\n",
              "48          ,      O\n",
              "49        the      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-73960bd1-91bc-434f-b841-9b455a52c91a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PART</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I.</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FRIENDS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>OF</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHILDHOOD</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Dr.</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Howard</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Archie</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>had</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>just</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>come</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>up</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>from</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>a</td>\n",
              "      <td>I-LOC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>game</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>of</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>pool</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>with</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Jewish</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>clothier</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>and</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>two</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>traveling</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>men</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>who</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>happened</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>to</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>be</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>staying</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>overnight</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Moonstone</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>.</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>His</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>offices</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>were</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Duke</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Block</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>over</td>\n",
              "      <td>B-PER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>drug</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>store</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>.</td>\n",
              "      <td>B-GPE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Larry</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73960bd1-91bc-434f-b841-9b455a52c91a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73960bd1-91bc-434f-b841-9b455a52c91a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73960bd1-91bc-434f-b841-9b455a52c91a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = \"PAD_TOKEN\"\n",
        "vocab_big = set([token for sentence_tokens in train_sents_tokens+test_sents_tokens\n",
        "    for token in sentence_tokens] + [token for token in list(df_test.PART)] )\n",
        "vocab_big.add(PAD_TOKEN)\n",
        "vocab_big = list(vocab_big)\n",
        "\n",
        "\n",
        "PAD_TAG = \"PAD_TAG\"\n",
        "tagset = set([tag\n",
        "            for sentence_tags in train_sents_tags+test_sents_tags\n",
        "            for tag in sentence_tags]+ [token for token in list(df_test.O)])\n",
        "tagset.add(PAD_TAG)\n",
        "tagset = list(tagset)\n",
        "\n",
        "print(f\"vocab size: {str(len(vocab_big))}, tagset_size: {str(len(tagset))}\")\n",
        "print(\"vocab samples:\", vocab_big[:5])\n",
        "print(\"tagset samples:\", tagset[:5])\n",
        "\n",
        "\n",
        "ix2word_big = dict(enumerate(vocab_big))\n",
        "word2ix_big = {w:ix for ix, w in ix2word_big.items()}\n",
        "\n",
        "ix2tag_big = dict(enumerate(tagset))\n",
        "tag2ix_big = {t:ix for ix, t in ix2tag_big.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBp_v1TcMkRy",
        "outputId": "f174a048-8a4d-40de-d5c3-e6d8ca58e7c6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size: 6647, tagset_size: 9\n",
            "vocab samples: ['uncombed', 'superintending', 'if', 'breasts', 'indeterminate']\n",
            "tagset samples: ['B-GPE', 'I-FAC', 'I-LOC', 'B-PER', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_score_test(src_tensor, tgt_tensor, model):\n",
        "    \"\"\"returns mean and joint scores on data batch\"\"\"\n",
        "    src = src_tensor.tolist()\n",
        "    tgt = tgt_tensor.tolist()\n",
        "\n",
        "    pred, _ = model(src_tensor)  # получаем предсказания модели на элементах батча\n",
        "    \n",
        "    batch_tok2tag2pred = []\n",
        "    batch_joint_accuracies = []\n",
        "    batch_mean_accuracies = []\n",
        "    for some_src, some_tgt, tags_predicted_digitized in zip(src, \n",
        "                                                            tgt, \n",
        "                                                            pred.argmax(dim=-1).tolist()):\n",
        "        # восстанавливаем токены, предсказанные и ожидаемые метки токенов, из их численных записей\n",
        "        tokens = list(map(ix2word_big.get, some_src))\n",
        "        tags_true = list(map(ix2tag_big.get, some_tgt))\n",
        "        tags_pred = list(map(ix2tag_big.get, tags_predicted_digitized))\n",
        "\n",
        "        tok2tag2pred = list(zip(tokens, tags_true, tags_pred))\n",
        "        \n",
        "        batch_tok2tag2pred.append(tok2tag2pred)\n",
        "\n",
        "        correct_preds = []  # чтобы хранить верные предсказания модели в человекочитаемом виде\n",
        "        actual_preds = []  # чтобы хранить *все* предсказания модели в человекочитаемом виде\n",
        "        for tok, gold_tag, pred_tag in tok2tag2pred:\n",
        "            if gold_tag == PAD_TAG:\n",
        "                # нас не волнуют ошибки на паддингах, тк они находятся за пределами предложения\n",
        "                break\n",
        "\n",
        "            batch_entry_w_prediction = (tok, gold_tag, pred_tag)\n",
        "            if gold_tag == pred_tag:\n",
        "                correct_preds.append(batch_entry_w_prediction)\n",
        "            actual_preds.append(batch_entry_w_prediction)\n",
        "\n",
        "        correct_preds_num = len(correct_preds)\n",
        "        joint_accuracy = int(correct_preds_num == len(actual_preds))  # 1 если не было ошибок, иначе 0\n",
        "        mean_accuracy = correct_preds_num/len(actual_preds) if actual_preds else 0  # доля верных ответов\n",
        "        batch_joint_accuracies.append(joint_accuracy)\n",
        "        batch_mean_accuracies.append(mean_accuracy)\n",
        "\n",
        "\n",
        "    return batch_tok2tag2pred, batch_joint_accuracies, batch_mean_accuracies\n",
        "\n"
      ],
      "metadata": {
        "id": "rK2AtU14FfzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# кодировать решение задания можно, например, в этой ячейке\n",
        "# например, ниже мы реализовали какую-то модель. \n",
        "# но вряд ли она сработеает лучше бейзлайна :)\n",
        "\n",
        "class LSTM_sigmoid(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, output_dim,\n",
        "                 emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = torch.nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = torch.nn.LSTM(emb_dim, hidden_dim,\n",
        "                            num_layers=2,  bidirectional=True,dropout = 0.2)\n",
        "        self.Dropout = torch.nn.Dropout(0.2)\n",
        "      #  self.fc = torch.nn.Linear(hidden_dim, 2*hidden_dim)\n",
        "        self.dc = torch.nn.Linear(2*hidden_dim,output_dim)\n",
        "    \n",
        "    def forward(self, in_seqs_batch):\n",
        "        embedded = self.emb(in_seqs_batch)\n",
        "        drop = self.Dropout(embedded)\n",
        "        rnn_out, hc = self.lstm(embedded)\n",
        "        #lin = self.fc(rnn_out)\n",
        "        out = self.dc(rnn_out)\n",
        "        return out, hc"
      ],
      "metadata": {
        "id": "4kR_Gnmoih1i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC4AtTwXmLWj"
      },
      "source": [
        "# кодировать решение задания можно, например, в этой ячейке\n",
        "# например, ниже мы реализовали какую-то модель. \n",
        "# но вряд ли она сработеает лучше бейзлайна :)\n",
        "\n",
        "class LSTM_sigmoid(torch.nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, output_dim,\n",
        "                 emb_dim, hidden_dim,num_layers,dropoutl,dropoutle):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb = torch.nn.Embedding(input_dim, emb_dim)\n",
        "        self.lstm = torch.nn.LSTM(emb_dim, hidden_dim,\n",
        "                            num_layers=num_layers,  bidirectional=True,dropout = dropoutl)\n",
        "        self.Dropout = torch.nn.Dropout(dropoutle)\n",
        "      #  self.fc = torch.nn.Linear(hidden_dim, 2*hidden_dim)\n",
        "        self.dc = torch.nn.Linear(2*hidden_dim,output_dim)\n",
        "    \n",
        "    def forward(self, in_seqs_batch):\n",
        "        embedded = self.emb(in_seqs_batch)\n",
        "        drop = self.Dropout(embedded)\n",
        "        rnn_out, hc = self.lstm(embedded)\n",
        "        #lin = self.fc(rnn_out)\n",
        "        out = self.dc(rnn_out)\n",
        "        return out, hc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egw-ymvhP7rR"
      },
      "source": [
        "Секция для обучения описанной вами модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcB-XaqEP-6I"
      },
      "source": [
        "# в этой ячейке можно написать код, \n",
        "emb_dim = 8000\n",
        "hidden_dim = 1024\n",
        "num_layers = 2\n",
        "dropoutl = 0.5\n",
        "dropoutle = 0.2\n",
        "\n",
        "EPOCHS = 15\n",
        "IMPATIENCE_LIMIT = 20\n",
        "\n",
        "# который будет обучать описанную вами модель\n",
        "model = LSTM_sigmoid(len(word2ix_big), len(tag2ix_big), emb_dim, hidden_dim,num_layers,dropoutl,dropoutle)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=tag2ix_big[PAD_TAG])\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "criterion = criterion.to(DEVICE)\n",
        "\n",
        "\n",
        "val_losses = [float(\"inf\")] * (IMPATIENCE_LIMIT + 1)\n",
        "for epoch_num in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, padded_batched_train_data, optimizer, criterion)\n",
        "    val_loss = test_epoch(model, padded_batched_val_data, optimizer, criterion)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    increasing_val_losses_tail_len = 0\n",
        "    for loss in val_losses[-IMPATIENCE_LIMIT:]:\n",
        "        if loss > val_losses[-IMPATIENCE_LIMIT-1]:\n",
        "            increasing_val_losses_tail_len += 1\n",
        "\n",
        "    print(f\"epoch {epoch_num}\", \n",
        "          f\"train loss {train_loss}\",\n",
        "          f\"val loss {val_loss}\",\n",
        "          f\"impatience {increasing_val_losses_tail_len} of {IMPATIENCE_LIMIT}\",\n",
        "          sep='\\t')\n",
        "\n",
        "    if increasing_val_losses_tail_len >= IMPATIENCE_LIMIT:\n",
        "        print(\"impatience stop in epoch\", epoch_num)\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5hEB9aQmNfD"
      },
      "source": [
        "Секция для вычисления предсказаний модели на отложенных данных."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_test =[]\n",
        "joint_accuracies=[]\n",
        "mean_accuracies=[]\n",
        "for src, tgt in padded_batched_test_data:\n",
        "    src_tensor = torch.LongTensor(src).to(DEVICE)\n",
        "    tgt_tensor = torch.LongTensor(tgt).to(DEVICE)\n",
        "\n",
        "    results_test, joints, means  = batch_score_test(src_tensor, tgt_tensor, model)\n",
        "\n",
        "    joint_accuracies.extend(joints)\n",
        "    mean_accuracies.extend(means)\n",
        "    model_results_test.extend(results_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "xlm5VlFYIMdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_results_test"
      ],
      "metadata": {
        "id": "-jHryjg-vWFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\"joint\": np.mean(joint_accuracies), \n",
        " \"mean\": np.mean(mean_accuracies)}"
      ],
      "metadata": {
        "id": "V9IKgu2zIqFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{'joint': 0.7048192771084337, 'mean': 0.9419308451190243}"
      ],
      "metadata": {
        "id": "uTpGUAnK-qEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X3qvLcx_fpQ"
      },
      "source": [
        "# в этой ячейке можно написать код, \n",
        "# который будет использовать обученную модель\n",
        "# для разметки проверочного датасета.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['token'] = df_test['PART'].apply(lambda x: word2ix_big[x])\n",
        "df_test['tag'] = df_test['O'].apply(lambda x: tag2ix_big[x])"
      ],
      "metadata": {
        "id": "ARPw3yMbL3pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head(10)"
      ],
      "metadata": {
        "id": "1iP3qPYrS5Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# первый вариант разбиения просто по 4 символа\n",
        "'''\n",
        "df_test_token_oll =[]\n",
        "df_test_tag_oll =[]\n",
        "for j in range(len(df_test)//4 + (0 if len(df_test)%4==0 else 1)):\n",
        "  i = j*4\n",
        "  df_test_token_oll.append([item for item in df_test.token[i:i+4]])\n",
        "  df_test_tag_oll.append([item for item in df_test.tag[i:i+4]])\n",
        "'''\n",
        "# второй вариант разбиения - по знакам препинания \n",
        "df_test_token,df_test_token_oll =[],[]\n",
        "df_test_tag,df_test_tag_oll =[], []\n",
        "\n",
        "for i, row in enumerate(df_test.PART):\n",
        "  #print(i, row, len(row) )\n",
        "  if len(row) > 12:\n",
        "    df_test_token.append(word2ix_big['I'])\n",
        "    df_test_tag.append(tag2ix_big['O'])\n",
        "  if row !='.' and row !='!' and row !='?' :\n",
        "    df_test_token.append(word2ix_big[row])\n",
        "    df_test_tag.append(tag2ix_big[df_test.O[i]])\n",
        "\n",
        "  else:\n",
        "\n",
        "    df_test_token.append(word2ix_big[row])\n",
        "    df_test_tag.append(tag2ix_big['O'])\n",
        "\n",
        "    df_test_token_oll.append(df_test_token)\n",
        "    df_test_tag_oll.append(df_test_tag)\n",
        "\n",
        "    df_test_token =[]\n",
        "    df_test_tag =[]\n",
        "\n",
        "\n",
        "test_data = list(zip(df_test_token_oll, df_test_tag_oll))\n",
        "\n",
        "batched_dataset_test = generate_batched_dataset(test_data, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "z4t1oyYnYhoY"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_batched_test_data_oll = pad_batched_dataset_of_sequences_pairs(batched_dataset_test, \n",
        "                                                                  word2ix_big[PAD_TOKEN],\n",
        "                                                                  tag2ix_big[PAD_TAG]) "
      ],
      "metadata": {
        "id": "7EbY0Kj7blJs"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_accuracies = []\n",
        "mean_accuracies = []\n",
        "t2t2t_accuracies = []\n",
        "for src, tgt in padded_batched_test_data_oll:\n",
        "    src_tensor = torch.LongTensor(src).to(DEVICE)\n",
        "    tgt_tensor = torch.LongTensor(tgt).to(DEVICE)\n",
        "\n",
        "    t2t2t, joints, means = batch_score_test(src_tensor, tgt_tensor,model)\n",
        "    joint_accuracies.extend(joints)\n",
        "    mean_accuracies.extend(means)\n",
        "    t2t2t_accuracies.extend(t2t2t)"
      ],
      "metadata": {
        "id": "dCUwKCr3cUbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.DataFrame([i for sm in t2t2t_accuracies for i in sm], \n",
        "             columns=[\"PART\", \"gold\", \"O\"])[[\"PART\", \"O\"]]\n",
        "\n",
        "sample_submission"
      ],
      "metadata": {
        "id": "ByX0TLcTf-Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.O.value_counts()"
      ],
      "metadata": {
        "id": "bBXvT4r1eXk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission.to_csv('sample_submission7.bio', index=False)"
      ],
      "metadata": {
        "id": "z21UaMgnnIjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iV49kdWfRunf"
      },
      "source": [
        "В описании задания на онлайн-платформе, в файле `...sample_solution.tsv` приложен пример файла с предсказаниями модели для сдачи задания."
      ]
    }
  ]
}